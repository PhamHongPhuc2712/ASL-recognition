{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# mediapipe for hand tracking\n",
        "import mediapipe as mp\n",
        "\n",
        "# gpu or cpu\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(\"=\" * 30)\n",
        "print(f\"Device in use: {device}\")\n",
        "print(\"Setup Complete.\")\n",
        "print(\"=\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive\"\n",
        "DATA_DIR = f\"{BASE_DIR}/data\"\n",
        "ASL_DIR = f\"{DATA_DIR}/asl_alphabet\"\n",
        "\n",
        "# create directories\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(ASL_DIR, exist_ok=True)\n",
        "\n",
        "print(\"✔ Created directories:\")\n",
        "print(DATA_DIR)\n",
        "print(ASL_DIR)\n",
        "\n",
        "print(\"\\n============================================================\")\n",
        "print(\" HOW TO ATTACH DATASETS TO THIS NOTEBOOK\")\n",
        "print(\"============================================================\")\n",
        "print(\"\"\"\n",
        "STEP 1 — Click 'Add Data' on the right sidebar.\n",
        "\n",
        "STEP 2 — Search & attach the following datasets:\n",
        "\n",
        "    ASL Alphabet Dataset (Grassknoted)\n",
        "    https://www.kaggle.com/datasets/grassknoted/asl-alphabet\n",
        "\n",
        "STEP 3 — After attaching all datasets, run the next cell to verify paths.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_path(possible_paths):\n",
        "    for p in possible_paths:\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "# ASL Alphabet dataset\n",
        "asl_path = find_path([\n",
        "    # Google Colab paths\n",
        "    \"/content/drive/MyDrive/data/asl_alphabet\",\n",
        "    \"/content/drive/MyDrive/data/asl_alphabet_train\",\n",
        "    \"/content/asl_alphabet\",\n",
        "])\n",
        "\n",
        "print(\"============================================================\")\n",
        "print(\" DATASET PATH CHECK RESULTS\")\n",
        "print(\"============================================================\")\n",
        "print(f\"ASL Alphabet found: {asl_path}\")\n",
        "\n",
        "if asl_path: print(\"✔ ASL Alphabet correctly attached.\")\n",
        "else: print(\"❌ ASL Alphabet NOT FOUND — attach using 'Add Data'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract 3D Landmarks from ASL Images\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "\n",
        "DATA_DIR = \"data/asl_alphabet\"  u# pdate to dataset path\n",
        "OUTPUT_DIR = \"output\"\n",
        "MAX_IMAGES_PER_CLASS = 1000\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Initialize MediaPipe Hands\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(\n",
        "    static_image_mode=True,\n",
        "    max_num_hands=1,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "# Get class folders (subdirectories in DATA_DIR)\n",
        "class_folders = sorted([f for f in os.listdir(DATA_DIR) \n",
        "                        if os.path.isdir(os.path.join(DATA_DIR, f))])\n",
        "print(f\"Found {len(class_folders)} classes: {class_folders}\")\n",
        "\n",
        "# Create label map\n",
        "label_map = {folder: idx for idx, folder in enumerate(class_folders)}\n",
        "print(f\"Label map: {label_map}\")\n",
        "\n",
        "# Storage\n",
        "landmarks_list = []\n",
        "labels_list = []\n",
        "no_hand_count = 0\n",
        "\n",
        "# Process each class\n",
        "for class_name in tqdm(class_folders, desc=\"Processing classes\"):\n",
        "    class_path = os.path.join(DATA_DIR, class_name)\n",
        "    images = [f for f in os.listdir(class_path) \n",
        "              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    \n",
        "    # Limit to MAX_IMAGES_PER_CLASS\n",
        "    images = images[:MAX_IMAGES_PER_CLASS]\n",
        "    \n",
        "    print(f\"Processing class '{class_name}': {len(images)} images\")\n",
        "    \n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "        \n",
        "        # Read and convert image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Process with MediaPipe\n",
        "        results = hands.process(img_rgb)\n",
        "        \n",
        "        if results.multi_hand_landmarks:\n",
        "            # Extract 21 landmarks (x, y, z for each = 63 values)\n",
        "            hand_landmarks = results.multi_hand_landmarks[0]\n",
        "            landmark_values = []\n",
        "            for landmark in hand_landmarks.landmark:\n",
        "                landmark_values.extend([landmark.x, landmark.y, landmark.z])\n",
        "            \n",
        "            landmarks_list.append(landmark_values)\n",
        "            labels_list.append(label_map[class_name])\n",
        "        else:\n",
        "            no_hand_count += 1\n",
        "            print(f\"  No hand detected: {img_name}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "landmarks_array = np.array(landmarks_list, dtype=np.float32)\n",
        "labels_array = np.array(labels_list, dtype=np.int32)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"\\n=== Results ===\")\n",
        "print(f\"Landmarks shape: {landmarks_array.shape} (expected: (N, 63))\")\n",
        "print(f\"Labels shape: {labels_array.shape} (expected: (N,))\")\n",
        "print(f\"Images with no hand detected: {no_hand_count}\")\n",
        "\n",
        "# Save outputs\n",
        "np.save(os.path.join(OUTPUT_DIR, \"landmarks.npy\"), landmarks_array)\n",
        "np.save(os.path.join(OUTPUT_DIR, \"labels.npy\"), labels_array)\n",
        "\n",
        "with open(os.path.join(OUTPUT_DIR, \"label_map.json\"), \"w\") as f:\n",
        "    json.dump(label_map, f, indent=2)\n",
        "\n",
        "print(f\"\\n✔ Saved to {OUTPUT_DIR}:\")\n",
        "print(f\"  - landmarks.npy\")\n",
        "print(f\"  - labels.npy\")\n",
        "print(f\"  - label_map.json\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
